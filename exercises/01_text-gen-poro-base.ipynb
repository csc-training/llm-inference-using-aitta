{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a5f00d1-1eb9-4a15-8c45-9c80949fdbff",
   "metadata": {},
   "source": [
    "# Text generation with LumiOpen/Poro-34B model\n",
    "\n",
    "We are going to start with a so-called \"base model\", pre-trained [**LumiOpen/Poro-34B**](https://huggingface.co/LumiOpen/Poro-34B). The task is to generate text with it. We are going to use API provided by Aitta inference platform. We need a Python client `aitta-client` to be able to use it. It has been already installed to this workspace. To see it's documentation, visit [PyPi](https://pypi.org/project/aitta-client/).\n",
    "\n",
    "We also need the API key. You can create it after logging into [Aitta](https://staging-aitta.2.rahtiapp.fi/public).\n",
    "\n",
    "<details open>\n",
    "<summary>Introduction for API key creation</summary>\n",
    "<br>\n",
    "1. Log in to the web frontend  \n",
    "<br>\n",
    "2. Navigate to the model page of the model for which to generate the token  \n",
    "<br>\n",
    "3. Open the tab titled 'API Key'  \n",
    "<br>\n",
    "4. Generate and copy the token   \n",
    "</details>\n",
    "\n",
    "After this we call your API key an \"access token\". We use it to configure Aitta client. Then it is possible to load model for usage. \n",
    "\n",
    "*You can save you API key for a safe place to be used in the future since it is valid over 80 days. Note that API keys are **model specific** at the moment.*\n",
    "\n",
    "**Let's start by loading library `aitta-client` and configuring Client-instance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246ce2e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install the aitta-client library\n",
    "!pip install --upgrade aitta-client\n",
    "\n",
    "# Alternatively, you can install all the libraries listed in the requirements.txt file\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5127cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your personal model-specific API key here  \n",
    "api_key = \"<API-key>\"\n",
    "\n",
    "# Security Note:  \n",
    "# In a typical setup, API keys should be stored securely using environment variables or secret management tools.  \n",
    "# However, since this temporary Jupyter notebook expires in 4 hours and does not support environment variables,  \n",
    "# we define the API key directly in this cell.  \n",
    "\n",
    "# To keep your API key safe, consider removing or clearing this cell after execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78f557d-a761-408b-af0c-f8b289337bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed libraries and modules\n",
    "from aitta_client import Model, Client, StaticAccessTokenSource\n",
    "\n",
    "# configure Client instance with API URL and access token\n",
    "token_source = StaticAccessTokenSource(api_key)\n",
    "client = Client(\"https://api-staging-aitta.2.rahtiapp.fi\", token_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97699c78",
   "metadata": {},
   "source": [
    "## Loading the model and some Jupyter notebook tips\n",
    "\n",
    "At the moment, only model-specific tokens are available. We can still look and see which models are available through created API key. \n",
    "\n",
    "**See available methods for the created client-instance**  \n",
    "* You can see available methods for created **client-instance** in Jupyter notebook code shell using `Tab` completion. Type the instance name followed by dot - like this `client.` -  and press `Tab-button` to see available methods. We use method `get_model_list` to see available models. \n",
    "\n",
    "**View method paramaters:**\n",
    "*  Option 1: To get detailed information about the method, including its parameters and docstring, you can append a `?` to the method name. For example write `client.get_model_list?` to a code cell and run it.\n",
    "* Option 2: When you type a method, like `client.get_model_list(`, and then press `Shift + Tab`, Jupyter will display a tooltip showing the method signature, including its parameters, expected types, and a short description if available. This is really helpful to quickly see what the method requires.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba55e68-618c-4113-803b-b8a11187c6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Try out here ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713f8a46-2835-4cf2-851d-926f6bebb907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the get_model_list method to retrieve the list of models\n",
    "model_list = client.get_model_list()\n",
    "\n",
    "# Iterate through the model list and print the model names/IDs\n",
    "for model_id in model_list:\n",
    "    print(model_id.id)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a86d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the LumiOpen/Poro model\n",
    "model = Model.load(\"LumiOpen/Poro\", client)\n",
    "\n",
    "print(model.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff59b7f-06e2-4dd2-bb50-f84dce466cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare inputs and parameters for a text completion inference task\n",
    "inputs = {\n",
    "    'input': 'Suomen paras kaupunki on'\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'do_sample': True,\n",
    "    'max_new_tokens': 20\n",
    "}\n",
    "\n",
    "print(f\"INPUT:\\n{inputs}\")\n",
    "\n",
    "# start the inference and wait for completion\n",
    "result = model.start_and_await_inference(inputs, params)\n",
    "print(f\"OUTPUT:\\n{result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638c6c8a-4d4b-440b-8274-8625e662ed4e",
   "metadata": {},
   "source": [
    "## Fine-Tuning generation parameters\n",
    "\n",
    "You can customize text generation by adding parameters to the `params` dictionary in the example code. The following options are currently supported when using the `start_and_await_inference` method and align with those used in [Hugging Face’s Transformers module](https://huggingface.co/docs/transformers/main_classes/text_generation) for text generation:\n",
    "\n",
    "**Controlling output length**\n",
    "* max_new_tokens\n",
    "* min_new_tokens\n",
    "* min_length\n",
    "* max_length\n",
    "\n",
    "**Adjusting the generation strategy**\n",
    "* do_sample: \n",
    "* num_beams\n",
    "* top_k\n",
    "\n",
    "**Modifying model output behavior**\n",
    "* temperature\n",
    "* top_p\n",
    " \n",
    "For more details on how these parameters work—including their minimum and maximum values, data types, and how certain parameters override others—refer to the [Hugging Face’s documentation](https://huggingface.co/docs/transformers/main_classes/text_generation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ffca60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare inputs and parameters for a text completion inference task\n",
    "inputs = {\n",
    "    'input': 'Suomen paras kaupunki on'\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'do_sample': True,\n",
    "    'max_new_tokens': 20,\n",
    "    #### Add parameters here to test how they affect generated response ####\n",
    "}\n",
    "\n",
    "print(f\"INPUT:\\n{inputs}\")\n",
    "\n",
    "# start the inference and wait for completion\n",
    "result = model.start_and_await_inference(inputs, params)\n",
    "print(f\"OUTPUT:\\n{result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af3ccd3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
