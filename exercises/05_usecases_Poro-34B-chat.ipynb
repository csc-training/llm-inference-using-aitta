{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8650a328-e15f-482d-be2c-c05ed7ba21d0",
   "metadata": {},
   "source": [
    "## Real use cases for chat-tuned models\n",
    "\n",
    "After the previous exercise, you are now capable of using the Poro-34B-chat model through the API that the `aitta_client` provides.\n",
    "\n",
    "After the client confugurations we will create a function to get response that takes a promt as an input. It uses always the same model and the role is user. Only the content varies. \n",
    "\n",
    "After configuring the client, we will create a function to get responses that take a prompt as input. You can also customize the maximum token count. It always uses the same model, and the role is \"user.\" Only the content varies. \n",
    "\n",
    "In this section, we will explore several real-world use cases where chat-tuned models can be applied. The following table of contents outlines the different use cases covered in this notebook.\n",
    "\n",
    "# Table of content\n",
    "1. [Sentiment analysis of feedback](#Sentiment-analysis-of-feedback)\n",
    "2. [Text summarization](#Text-summarization)\n",
    "3. [Retrieving relevant research papers](#Retrieving-relevant-research-papers)\n",
    "4. [Named entity recognition (NER)](#NER)\n",
    "5. [Extracting key topics](#Extracting-key-topics)\n",
    "6. [Refining academic writing](#Refining-academic-writing)\n",
    "7. [Translation from Finnish to English](#Translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eada50d-edbb-474a-9dda-ef7b32d70d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"<API-KEY>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c7149c-3317-49e4-b952-3cb1c7a35a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aitta_client import Model, Client, StaticAccessTokenSource\n",
    "import openai\n",
    "import IPython\n",
    "\n",
    "\n",
    "token_source = StaticAccessTokenSource(api_key)\n",
    "aitta_client = Client(\"https://api-staging-aitta.2.rahtiapp.fi\", token_source)\n",
    "\n",
    "# load the \"allenai/OLMo-7B-0724-Instruct\" model\n",
    "model = Model.load(\"LumiOpen/Poro-34B-chat\", aitta_client)\n",
    "print(model.description)\n",
    "\n",
    "# configure OpenAI client to use the Aitta OpenAI compatibility endpoints\n",
    "client = openai.OpenAI(api_key=token_source.get_access_token(), base_url=model.openai_api_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fcf2f6-4b4a-422c-881d-ec3643f060a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(prompt, max_completion_tokens=100):\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        model=model.id,\n",
    "        n=1,\n",
    "        max_completion_tokens=max_completion_tokens,\n",
    "        stream=False  # response streaming is currently not supported by Aitta\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ab2899-117a-4062-a886-e4830f9b58c7",
   "metadata": {},
   "source": [
    "### 1. Sentiment analysis of feedback   <a class=\"anchor\" id=\"Sentiment-analysis-of-feedback\"></a>\n",
    "\n",
    "Sentiment analysis is a natural language processing (NLP) technique used to determine the emotional tone behind text. It classifies text into categories such as **Positive, Neutral, or Negative**.\n",
    "\n",
    "In this example, we use an LLM to process research-related feedback and automatically assign sentiment labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbf53ae-ebee-426f-85bd-bbcd287c991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructs = \"\"\"\n",
    "You are an assistant who classifies text into different categories by sentiment. \n",
    "Classify listed feedbacks into neutral, negative or positive.\n",
    "Format your response as JSON with 'feedback_id' and 'category' keys.\n",
    "Provide only the JSON.\n",
    "\"\"\"\n",
    "\n",
    "feedback_texts = \"\"\"\n",
    "1. \"The research process was smooth, and I got the results I needed quickly.\"\n",
    "2. \"It took a long time to receive my dataset, but the quality was acceptable.\"\n",
    "3. \"I was extremely frustrated with the lack of communication and support.\"\n",
    "4. \"The documentation was helpful, though I had to figure out some details myself.\"\n",
    "5. \"Fantastic support and very well-organized data!\"\n",
    "\"\"\"\n",
    "\n",
    "prompt = instructs + feedback_texts\n",
    "# Get sentiment analysis response\n",
    "sentiment_analysis = get_response(prompt)\n",
    "IPython.display.Markdown(sentiment_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8852c9ef-871f-41b8-a6d9-6d4989728e5f",
   "metadata": {},
   "source": [
    "### 2. Text summarization <a class=\"anchor\" id=\"Text-summarization\"></a>\n",
    "\n",
    "LLMs can quickly extract key insights from long research papers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6a8f18-896d-4d71-9673-26ba4934a400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_paper(abstract):\n",
    "    prompt = f\"\"\"\n",
    "    You are a helpful summariser.\n",
    "    Summarize the key findings and contributions in a three bullet points of the following research \n",
    "    abstract:\\n{abstract}. Keep your answer clear and concise.\"\"\"\n",
    "    return get_response(prompt)\n",
    "\n",
    "#https://arxiv.org/pdf/1706.03762: Attention Is All You Need\n",
    "abstract = \"\"\"\n",
    "The dominant sequence transduction models are based on complex recurrent or\n",
    "convolutional neural networks that include an encoder and a decoder. The best\n",
    "performing models also connect the encoder and decoder through an attention\n",
    "mechanism. We propose a new simple network architecture, the Transformer,\n",
    "based solely on attention mechanisms, dispensing with recurrence and convolutions\n",
    "entirely. Experiments on two machine translation tasks show these models to\n",
    "be superior in quality while being more parallelizable and requiring significantly\n",
    "less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\n",
    "to-German translation task, improving over the existing best results, including\n",
    "ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\n",
    "our model establishes a new single-model state-of-the-art BLEU score of 41.8 after\n",
    "training for 3.5 days on eight GPUs, a small fraction of the training costs of the\n",
    "best models from the literature. We show that the Transformer generalizes well to\n",
    "other tasks by applying it successfully to English constituency parsing both with\n",
    "large and limited training data\n",
    "\"\"\"\n",
    "\n",
    "summary = summarize_paper(abstract)\n",
    "IPython.display.Markdown(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc631671-7ea0-4772-b268-74db28435b28",
   "metadata": {},
   "source": [
    "### 3. Retrieving relevant research papers <a class=\"anchor\" id=\"Retrieving-relevant-research-papers\"></a>\n",
    "\n",
    "Researchers often need to find relevant papers based on specific topics, keywords, or publication years. Manually searching through large datasets can be time-consuming, but LLMs can assist by understanding queries and retrieving relevant research papers.  \n",
    "\n",
    "In this example, we use an LLM to search through a small mock dataset of research papers. The model identifies papers related to a given query, such as topics on **climate change, biodiversity or agriculture**, and filters results accordingly.\n",
    "\n",
    "After that we try to create a mock dataset using LLM.\n",
    "\n",
    "*Mock data means random data that follows a predefined column format*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd11e8d0-9305-40f6-8db2-06cd29316e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock dataset of research papers, created by AI\n",
    "research_papers = [\n",
    "    {\"title\": \"Impact of Climate Change on Marine Life\", \"year\": 2023, \"keywords\": [\"climate change\", \"marine life\"]},\n",
    "    {\"title\": \"Biodiversity and Ecosystem Services in Urban Areas\", \"year\": 2022, \"keywords\": [\"biodiversity\", \"urban areas\"]},\n",
    "    {\"title\": \"Climate Change Effects on Agriculture\", \"year\": 2021, \"keywords\": [\"climate change\", \"agriculture\"]},\n",
    "    {\"title\": \"Biodiversity Loss in Coral Reef Ecosystems\", \"year\": 2023, \"keywords\": [\"biodiversity\", \"coral reefs\", \"climate change\"]},\n",
    "    {\"title\": \"Sustainable Energy Solutions and Climate Mitigation\", \"year\": 2022, \"keywords\": [\"renewable energy\", \"climate change\", \"sustainability\"]},\n",
    "    {\"title\": \"Conservation Strategies for Endangered Species\", \"year\": 2023, \"keywords\": [\"conservation\", \"biodiversity\", \"endangered species\"]}\n",
    "]\n",
    "\n",
    "def query_research_papers(query, dataset):\n",
    "    prompt = f\"Given the following research papers, find those relevant to the query: {query}\\nDataset: {dataset}\"\n",
    "    return get_response(prompt)\n",
    "\n",
    "query = \"Find all papers published on climate change in year 2023. List the papers by titles without description.\"\n",
    "response = query_research_papers(query, research_papers)\n",
    "#print(f\"Query Response: {response}\")\n",
    "IPython.display.Markdown(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e95699",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Do not respond as an assistant. Ensure strict JSON compliance.\n",
    "Generate a mock dataset of research papers about climate change from the years 2015 to 2025.\n",
    "\n",
    "Return the output **strictly** as a valid JSON array, without any additional text, explanations, or formatting. The JSON array should contain multiple objects, each with the following keys:\n",
    "- \"title\" (string): The research paper title.\n",
    "- \"year\" (integer): A publication year between 2015 and 2025.\n",
    "- \"keywords\" (array of strings): Relevant keywords for the paper.\n",
    "\n",
    "### Output Format:\n",
    "```json\n",
    "[\n",
    "  {\"title\": \"Impact of Climate Change on Marine Life\", \"year\": 2018, \"keywords\": [\"climate change\", \"marine life\"]},\n",
    "  {\"title\": \"AI and Climate Modeling\", \"year\": 2023, \"keywords\": [\"AI\", \"climate modeling\"]}\n",
    "]\n",
    "DO NOT include any explanations, introductions, or additional text. Only return valid JSON with 5 objects. \n",
    "\"\"\"\n",
    "create_mock_dataset = get_response(prompt, 300)\n",
    "IPython.display.Markdown(create_mock_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9218ca0d-d80c-4311-9012-29d165ba70ff",
   "metadata": {},
   "source": [
    "### 4. Named entity recognition (NER) for extracting key information <a class=\"anchor\" id=\"NER\"></a>\n",
    "\n",
    "Named Entity Recognition (NER) is a natural language processing (NLP) task that involves identifying and classifying key entities in a given text. These entities can include people, organizations, locations, dates, and other specific terms that essential for understanding the content. NER is widely used in information extraction systems, question answering, and text summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e5585a-cfc3-4d9b-b69e-cd38722f95c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://okm.fi/en/-/new-supercomputer-to-be-located-in-kajaani-finland-gains-stronger-role-in-ai-research\n",
    "text = \"\"\"\n",
    "The European High Performance Computing Joint Undertaking (EuroHPC) has selected the sites \n",
    "that will host the new European AI Factories. The AI factory consists of a supercomputer that\n",
    "provides world-class computing power as well as completely new data sources together with \n",
    "a service centre and talent pool.\n",
    "\n",
    "Of the seven funded projects, one belongs to the LUMI consortium, which is led by Finland. \n",
    "The LUMI AI Factory will be hosted by CSC - IT Center for Science and located in Kajaani.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Identify and list the key named entities (people, organizations, places) in the following text:\\n{text}. \n",
    "Prove key entities in concise way.\n",
    "\"\"\"\n",
    "\n",
    "entities = get_response(prompt, 200)\n",
    "#print(f\"Named Entities: {entities}\")\n",
    "IPython.display.Markdown(entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c956483-a3d1-496c-8b7c-ec6207112761",
   "metadata": {},
   "source": [
    "### 5. Extracting key topics from research papers <a class=\"anchor\" id=\"Extracting-key-topics\"></a>\n",
    "\n",
    "In this section, we use an LLM to automatically extract the most important keywords from a research paper. Keywords are essential for identifying the core topics and concepts of the text, which is valuable for summarizing and categorizing research. The function `extract_keywords()` takes the input text, constructs a prompt to instruct the model to identify key terms, and returns a list of significant keywords. This process helps quickly understand the main focus of the research without needing to read the entire paper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0db28dd-3fb1-4d12-90a3-0f0fd795828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(text):\n",
    "    prompt = f\"Extract 5 most important keywords from the following abstract:\\n{text}\"\n",
    "    return get_response(prompt)\n",
    "\n",
    "#https://www.researchgate.net/publication/361665646_Evaluating_GPU_Programming_Models_for_the_LUMI_Supercomputer\n",
    "research_abstract = \"\"\"\n",
    "It is common in the HPC community that the achieved performance with just CPUs is limited \n",
    "for many computational cases. The EuroHPC pre-exascale and the coming exascale systems are \n",
    "mainly focused on accelerators, and some of the largest upcoming supercomputers such as LUMI \n",
    "and Frontier will be powered by AMD Instinct™ accelerators. However, these new systems create\n",
    "many challenges for developers who are not familiar with the new ecosystem or with the \n",
    "required programming models that can be used to program for heterogeneous architectures. \n",
    "In this paper, we present some of the more well-known programming models to program for \n",
    "current and future GPU systems. We then measure the performance of each approach using a \n",
    "benchmark and a mini-app, test with various compilers, and tune the codes where necessary. \n",
    "Finally, we compare the performance, where possible, between the NVIDIA Volta (V100), \n",
    "Ampere (A100) GPUs, and the AMD MI100 GPU.\n",
    "\"\"\"\n",
    "\n",
    "keywords = extract_keywords(research_abstract)\n",
    "\n",
    "IPython.display.Markdown(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f582da-12fb-4e74-bb5a-18c96703ca34",
   "metadata": {},
   "source": [
    "### 6. Refining academic writing <a class=\"anchor\" id=\"Refining-academic-writing\"></a>\n",
    "\n",
    "In this section, we use an LLM to improve the clarity, grammar, and readability of a rough draft of an academic research paragraph. The function `improve_writing()` sends a prompt to the model, instructing it to enhance the provided text while preserving scientific accuracy. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea8f93a-74ae-4b3c-a832-f1809e8dfbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draft of a research paragraph\n",
    "rough_paragraph = \"\"\"\n",
    "The usage of AI in biomedical sciences is growing rapidly. \n",
    "However, due to the complexity of the models and the necessity of big data, \n",
    "it sometimes leads to issues in explainability and reproducibility of results. \n",
    "As a consequence, scientists are investigating methods to make AI models more transparent, \n",
    "which in turn could improve trust in AI-based medical diagnoses.\n",
    "\"\"\"\n",
    "\n",
    "# Prompt for improving clarity, grammar, and readability\n",
    "def improve_writing(text):\n",
    "    prompt = f\"\"\"\n",
    "    You excell at academic writing. Improve the clarity, grammar, and readability of the following \n",
    "    academic text while maintaining its scientific accuracy:\\n{text}\n",
    "    Response strictly the corrected text.\n",
    "    \"\"\"\n",
    "    return get_response(prompt)\n",
    "\n",
    "# Generate the improved version\n",
    "improved_text = improve_writing(rough_paragraph)\n",
    "IPython.display.Markdown(improved_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64dbbd8-673b-4424-adae-06f4dd364b0b",
   "metadata": {},
   "source": [
    "### 7. Translation from Finnish to English <a class=\"anchor\" id=\"Translation\"></a>\n",
    "\n",
    "In this section, we use an LLM to translate text from Finnish to English. The function `translate()` sends a prompt to the model, instructing it to translate the provided text into English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5452fa6-7e06-4a24-a9da-ce804875b298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text):\n",
    "    prompt = f\"Translate the following text from Finnish to English:\\n{text}\"\n",
    "    return get_response(prompt)\n",
    "\n",
    "finnish_text = \"\"\"\n",
    "Tekoälyn soveltaminen terveydenhuollossa tarjoaa merkittäviä mahdollisuuksia, mutta samalla se tuo mukanaan myös haasteita, \n",
    "kuten mallien läpinäkyvyyden puutteen ja tulosten toistettavuuden ongelmat. Näiden haasteiden ratkaisemiseksi tutkijat \n",
    "kehittävät keinoja, joilla tekoälyn mallit olisivat ymmärrettävämpiä ja luotettavampia.\n",
    "\"\"\"\n",
    "\n",
    "translated_text = translate(finnish_text)\n",
    "\n",
    "IPython.display.Markdown(translated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
