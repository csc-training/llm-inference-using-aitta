{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to using Large Language Models through inference platform Aitta\n",
    "\n",
    "## Course introduction - what is this course about\n",
    "\n",
    "In this concise online course, you'll learn the basics of using LLMs and their application through Lumi AI Factory's (LAIF) inference platform, Aitta. This course includes both theoretical material and interactive coding exercises. We will utilize models already available in Aitta-platform via API client using Python libraries [`aitta-client`](https://pypi.org/project/aitta-client/) and [`openai`](https://pypi.org/project/openai/). Aitta already offers some models for you to use, and future features will include the ability to upload models and create embeddings.\n",
    "\n",
    "> Aitta AI platform is still under development, so occasional issues may occur, especially with many users. Scalability improvements are in development. \n",
    "\n",
    "We'll provide a brief overview of model training and the basics of using them (inference) across different setups. **The primary focus will be on exploring Aitta and harnessing GPU power through its API for LLM inference.**\n",
    "\n",
    "This course is specifically centered on using LLMs with textual data. Other AI modalities and model types are not covered. While we touch on model training in the material, there are no hands-on exercises dedicated to this topic. \n",
    "\n",
    "\n",
    "## Course setup and prequisites - what do you need to complete this course\n",
    "\n",
    "Theory will be provided in CSC-github. Some prior knowledge of machine learning and natural language processing will be beneficial. During the theoretical parts, you will be guided to do related coding exercises. Basic knowledge of Python programming and Jupyter notebooks is required for the exercises.\n",
    "\n",
    "Coding exercises are available through [CSC's Noppe service](https://noppe.2.rahtiapp.fi/welcome) for interactive web based applications ([CSC Docs](https://docs.csc.fi/cloud/noppe/)). A dedicated workspace is set up for this course, allowing you to utilize an inference platform [Aitta](https://staging-aitta.2.rahtiapp.fi/) within a Jupyter notebook environment.  For more information on using Jupyter Notebooks, visit [Jupyter Documentation](https://docs.jupyter.org/en/latest/index.html). To access both the Noppe and Aitta webpages, you need a CSC account or Haka credits.\n",
    "\n",
    "If you prefer to complete Jupyter notebook exercises in your own environment, ensure you have Python 3.11 or higher, along with the libraries listed in the [requirements.txt](../exercises/requirements.txt) file. \n",
    "\n",
    "\n",
    "## Table of content of this course\n",
    "\n",
    "* **[1. Large Language Models (LLMs)](./01_LLMs.ipynb)**\n",
    "    * Brief introduction to large language models\n",
    "    * Overview of training phases: pre-training and fine-tuning\n",
    "    * Exploration of open-source LLMs\n",
    "\n",
    "* **[2. Inference - Using Trained LLMs](./02_inference.ipynb)**\n",
    "    * What is inference?\n",
    "    * Hardware and memory requirements for inference\n",
    "    * LUMI Supercomputer and hardware for inference\n",
    "    * Inference deployment options\n",
    "\n",
    "* **[3. Aitta - Inference platform](./03_aitta.ipynb)**\n",
    "    * Introduction to Aitta \n",
    "    * Understanding Aitta API and Python Client\n",
    "    * API integration\n",
    "    * Resource management\n",
    "    * Using chat-based LLMs with API provided by Aitta\n",
    "    * Exercise 0: Visit Aitta website\n",
    "    * Exercise 1: Generate text with LumiOpen/Poro-34B\n",
    "    * Exercise 2: Generate chat completions with LumiOpen/Poro-34B-chat\n",
    "    * Exercise 3: Tokenize text using LumiOpen/Poro-34B model's tokenizer\n",
    "\n",
    "\n",
    "* **[4. Usecases of LLM](./04_usecases_of_llms.ipynb)**\n",
    "    * General overview of different use case options\n",
    "    * Prompt engineering and optimization\n",
    "    * Challenges in LLM inference \n",
    "    * About RAG applications \n",
    "    * Exercise 4: Prompt testing\n",
    "    * Exercise 5: Real usecases for chat-tuned models\n",
    "    * Exercise 6: Simple example for multiple papers summarization\n",
    "    * Exercise 7: Basics of RAG\n",
    "    * Exercise 8: Simple RAG example using FAISS\n",
    "    * Feedback survey\n",
    "    \n",
    "Next, you can move on to [**Large Language Models (LLMs)**](./01_LLMs.ipynb) section to understand how these powerful models are trained and their key capabilities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
