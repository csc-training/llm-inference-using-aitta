{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Aitta AI inference platform\n",
    "\n",
    "[**Aitta**](https://staging-aitta.2.rahtiapp.fi/) is an AI inference platform with a model catalog designed for research and development purposes. Aitta offers you an easy way to utilize powerful LLMs and other AI models through Python API client. \n",
    "\n",
    "Aitta is easy to use: it has a Web UI (user interface) and a simple OpenAI compatible REST API. To be able to use this API, you need to log in to [Aitta's webpage](https://staging-aitta.2.rahtiapp.fi/). Then you are able to create API keys that enable you to access the models.\n",
    "\n",
    "While its development is ongoing and uploading custom models is not available, Aitta already provides models for you to explore through the web UI and API endpoints using Python libraries [`aitta-client`](https://pypi.org/project/aitta-client/) and [`openai`](https://pypi.org/project/openai/). In the near future it will also be possible to create embeddings (numerical representations of real-world objects) of the data using Aitta. \n",
    "\n",
    "\n",
    "## Understanding Aitta API and Python Client\n",
    "\n",
    "Aitta makes models and inference tasks available via a REST API, so you can directly communicate with it via HTTP if you want. However, you don't need to know how to use REST APIs or understand all the HTTP methods involved. With just a few lines of code, you can utilize the Python client created by the Aitta developers.\n",
    "\n",
    "Aitta makes models and inference tasks available via a REST API, allowing direct communication via HTTP. You can access the [AITTA API reference documentation](https://api-staging-aitta.2.rahtiapp.fi/docs) to explore details about endpoints, parameters, and responses.\n",
    "\n",
    "> **API-term definitions:**\n",
    "> \n",
    "> - **API (Application Programming Interface)**: An API allows one program to request services or data from another program, without needing to understand its internal workings.\n",
    "> - **REST (Representational State Transfer) API**: A REST API is a type of API that allows different applications to communicate with each other over HTTP requests in a simple, scalable, and stateless manner.\n",
    "> - **API Endpoint**: Specific URL within an API to access or store specific resources or issue a particular command to the system.\n",
    "> - **API client**: A program or tool used to communicate with APIs.\n",
    "\n",
    "**However, you don't need to be familiar with REST APIs or HTTP methods. Instead, you can use the Python client developed by the Aitta team to interact with the API in just a few lines of code.**\n",
    "\n",
    "## Resource management\n",
    "\n",
    "Aitta allocates resources on demand from the European top supercomputer instead of wasting money and energy by reserving heavy static servers, which are possibly idling most of the time, for running the models. At the moment, supercomputer resources are allocated automatically and freed after a certain period if time. \n",
    "\n",
    "Since Aitta is still in development phase, it doesn't consume users' billing units. When the service is officially launched, this will change.\n",
    "\n",
    "\n",
    "## Using chat-based LLMs with Aitta API\n",
    "\n",
    "Using the model through the API with the Python client is straightforward and user-friendly, requiring only a few lines of code to get started. \n",
    "\n",
    "First, we are going to obtain an API key and configure the Aitta client with it, load the model and set up the OpenAI client for compatibility. Once these steps are completed, you can perform chat completions - send prompts and receive responses.\n",
    "\n",
    "\n",
    "In the upcoming exercises, we will go through step by step the process of using the Python client to integrate and work with LLMs via the Aitta API, helping you become comfortable with the workflow.\n",
    "\n",
    "The diagram below illustrates the process of making an API call for chat completions for the first time:\n",
    "\n",
    "\n",
    "![first-api-call-for-chatcompletions](./images/API-chat-completions-bold.png)\n",
    "\n",
    "*Generating the first response might take some time. Starting a new worker in the LUMI Supercomputer takes some time.*\n",
    "\n",
    "\n",
    "## Aitta as one of the MLOps tools\n",
    "\n",
    "Aitta is here to complement provided [MLOps](https://en.wikipedia.org/wiki/MLOps) (Machine Learning Operations) tools. One of the existing MLOps tools is MLFlow; you can check this [tutorial](https://github.com/CSCfi/puhti_mlflow_tutorial) for using MLFlow in CSC's supercomputers. \n",
    "\n",
    "\n",
    "## Exercise time!\n",
    "\n",
    "\n",
    "Coding exercises are available through [CSC's Noppe service](https://noppe.2.rahtiapp.fi/welcome) for interactive web based applications ([CSC Docs](https://docs.csc.fi/cloud/noppe/)). A dedicated workspace is set up for this course. Basic knowledge of Python programming and Jupyter notebooks is required for the exercises. For more information on using Jupyter Notebooks, visit [Jupyter Documentation](https://docs.jupyter.org/en/latest/index.html). The accepted authentication methods to access Noppe are CSC account, Haka, Virtu, or MOOC.fi credits.\n",
    "\n",
    "**[Instructions on how to use Noppe]**\n",
    "\n",
    "**Activated Noppe instance is valid for 4 hours!**\n",
    "\n",
    "\n",
    "###  Exercise 0: Log into Aitta website\n",
    "\n",
    "First you are going to log into Aitta website and follow instructions: \n",
    "\n",
    "* Log into Aitta website https://staging-aitta.2.rahtiapp.fi/public\n",
    "* Which models can you find? Can you input some text in the Web UI after choosing a model to use?\n",
    "* Do you find the place for API key generation?\n",
    "* Take a look around, can you find documentation for Aitta Client usage? \n",
    "\n",
    "\n",
    "### Exercise 1: Text generation with LumiOpen/Poro-34B model\n",
    "\n",
    "Log into https://noppe.2.rahtiapp.fi/welcome. You will land to main page where you can see all available workspaces. **[More guidance on starting a workspace]**\n",
    "\n",
    "* Log into Noppe and choose the right working space **NAME HERE** (workspace not yet set up)\n",
    "* Try to use Poro base model for text generation **[01_text-gen-poro-base.ipynb](../exercises/01_text-gen-poro-base.ipynb)**\n",
    "* Refine parameters that affect the output\n",
    "\n",
    "### Exercise 2: Chat completions with LumiOpen/Poro-34B-chat model\n",
    "\n",
    "* Try to use Poro chat model **[02_Poro-34B-chat-completions.ipynb](../exercises/02_Poro-34B-chat-completions.ipynb)**\n",
    "* Refine parameters that affect the output\n",
    "\n",
    "### Exercise 3: Tokenize text using LumiOpen/Poro-34B model's tokenizer\n",
    "* See how text is tokenized using LumiOpen/Poro-34B model's tokenizer in the **[03_poro-tokenizer.ipynb](../exercises/03_poro-tokenizer.ipynb)**\n",
    "\n",
    "**NOTE!**   \n",
    "\n",
    "Your work is not saved in Noppe. You should download preferred files if you want to retain your work after Noppe instance times out. \n",
    "\n",
    "You can download a single file by going to the **File-menu** or by right-clicking the file and selecting **Download** from the dropdown menu.\n",
    "\n",
    "![dowload file](./images/download_noppe.png)\n",
    "\n",
    "\n",
    "**Be careful not to share your API Key anywhere.**\n",
    "\n",
    "## Next steps\n",
    "\n",
    "Now we have covered first steps of using API for generating text with LLMs. You can move on to next section,  [**Usecases of LLMs**](./04_usecases_of_llms.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
